{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "titanic=pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First take a look at the data types and non-null entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "None\n",
      "             count        mean         std   min       25%       50%    75%  \\\n",
      "PassengerId  891.0  446.000000  257.353842  1.00  223.5000  446.0000  668.5   \n",
      "Survived     891.0    0.383838    0.486592  0.00    0.0000    0.0000    1.0   \n",
      "Pclass       891.0    2.308642    0.836071  1.00    2.0000    3.0000    3.0   \n",
      "Age          714.0   29.699118   14.526497  0.42       NaN       NaN    NaN   \n",
      "SibSp        891.0    0.523008    1.102743  0.00    0.0000    0.0000    1.0   \n",
      "Parch        891.0    0.381594    0.806057  0.00    0.0000    0.0000    0.0   \n",
      "Fare         891.0   32.204208   49.693429  0.00    7.9104   14.4542   31.0   \n",
      "\n",
      "                  max  \n",
      "PassengerId  891.0000  \n",
      "Survived       1.0000  \n",
      "Pclass         3.0000  \n",
      "Age           80.0000  \n",
      "SibSp          8.0000  \n",
      "Parch          6.0000  \n",
      "Fare         512.3292  \n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "print titanic.info()\n",
    "\n",
    "print titanic.describe().T\n",
    "\n",
    "print titanic.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Some observations from looking at the above data include:\n",
    "\n",
    " - Age contains missing values for a relatively small set of the population. We will need to impute numbers for this somehow.\n",
    " - Cabin contains many, many missing values. The first character also likely contains information on the deck location\n",
    " - Embarked contains two missing values. We likely need to account for this, but likely through a simple missing dummy/factor\n",
    " - There is quite a bit of information in the name field that could become useful. For example, while there is a sibling/spouse    field, it may be helpful to identify/separate whether it is a sibling or a spouse onboard using the \"Miss/Mrs.\" feature as      well as knowing that female spouses have their husbands' name in the registry, so we can find a match.\n",
    " - Variables to turn into factors include Pclass, (potentially, given likely discontinuous breaks) Age, and Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with converting the Sex values into a boolean; just feels cleaner to start there, especially if we are going to be working with this variable when cleaning other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic.Sex.replace(['male','female'],[True,False], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's fill in the missing Age values. We have a pretty full dataset (about 7/8ths), so we can probably get away, in a first pass, with doing some simple stratification and assuming ages are missing-at-random within those strata. For now, let's stratify on gender and class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print titanic.Age.mean()\n",
    "    \n",
    "titanic.Age= titanic.groupby(['Sex','Pclass'])[['Age']].transform(lambda x: x.fillna(x.mean()))\n",
    "titanic.Fare= titanic.groupby(['Pclass'])[['Fare']].transform(lambda x: x.fillna(x.mean()))\n",
    "#print titanic.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next, deal with converting Pclass into something we can work with, and also create dummies for deck location and port of embarkation (when found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_class=pd.get_dummies(titanic.Pclass,prefix='Pclass',dummy_na=False)\n",
    "titanic=pd.merge(titanic,titanic_class,on=titanic['PassengerId'])\n",
    "titanic=pd.merge(titanic,pd.get_dummies(titanic.Embarked, prefix='Emb', dummy_na=True), on=titanic['PassengerId'])\n",
    "\n",
    "titanic['Floor']=titanic['Cabin'].str.extract('^([A-Z])', expand=False)\n",
    "#T only appears once, so let's just scrub that to NaN\n",
    "titanic['Floor'].replace(to_replace='T',value=np.NaN ,inplace=True)\n",
    "titanic['Floor'].replace(to_replace=['A','B','C','D','E','F','G'],value=['AB','AB','CD','CD','EFG','EFG','EFG'] ,inplace=True)\n",
    "\n",
    "titanic=pd.merge(titanic,pd.get_dummies(titanic.Floor, prefix=\"Fl\", dummy_na=True),on=titanic['PassengerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic['Age_cut']=pd.cut(titanic['Age'],[0,14.9,54.9,99], labels=['C','A','S'])\n",
    "titanic=pd.merge(titanic,pd.get_dummies(titanic.Age_cut, prefix=\"Age_ct\", dummy_na=False),on=titanic['PassengerId'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, before going forward I'd really like to be able to separate spouses from siblings in that variable. One way to do this is that we see married women have their husbands' names located outside of parentheses within their own name. We create a new variable that just contains the words outside of the parentheses, and see if these match any other names in the dataset. \n",
    "\n",
    "Additionally, from just scanning the names in the dataset, it appears that titles always come between the comma after the last name and a period. This is a perfect opportunity to use regular expressions to extract that title and turn it into a feature we can consider in analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re as re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic['Title']=titanic['Name'].str.extract(', (.*)\\.', expand=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there is some cleaning that could be done here. We'll do three things:\n",
    "1.) Turn French ladies' titles into English ones\n",
    "2.) Aggregate Military titles\n",
    "3.) For all remaining titles with count less than five, create remainder bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr              517\n",
      "Miss            184\n",
      "Mrs             126\n",
      "Master           40\n",
      "Dr                7\n",
      "Rev               6\n",
      "Mil               5\n",
      "Jonkheer          1\n",
      "Ms                1\n",
      "Lady              1\n",
      "Don               1\n",
      "the Countess      1\n",
      "Sir               1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "titanic['Title'].replace(to_replace='Mrs\\. .*',value='Mrs', inplace=True, regex=True)\n",
    "titanic.loc[titanic.Title.isin(['Col','Major','Capt']),['Title']]='Mil'\n",
    "titanic.loc[titanic.Title=='Mlle',['Title']]='Miss'\n",
    "titanic.loc[titanic.Title=='Mme',['Title']]='Mrs'\n",
    "\n",
    "print titanic.Title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 38 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null bool\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "Pclass_1       891 non-null float64\n",
      "Pclass_2       891 non-null float64\n",
      "Pclass_3       891 non-null float64\n",
      "Emb_C          891 non-null float64\n",
      "Emb_Q          891 non-null float64\n",
      "Emb_S          891 non-null float64\n",
      "Emb_nan        891 non-null float64\n",
      "Floor          203 non-null object\n",
      "Fl_AB          891 non-null float64\n",
      "Fl_CD          891 non-null float64\n",
      "Fl_EFG         891 non-null float64\n",
      "Fl_nan         891 non-null float64\n",
      "Age_cut        891 non-null object\n",
      "Age_ct_C       891 non-null float64\n",
      "Age_ct_A       891 non-null float64\n",
      "Age_ct_S       891 non-null float64\n",
      "Title          891 non-null object\n",
      "Title_ct       891 non-null int64\n",
      "Ti_Dr          891 non-null float64\n",
      "Ti_Master      891 non-null float64\n",
      "Ti_Mil         891 non-null float64\n",
      "Ti_Miss        891 non-null float64\n",
      "Ti_Mr          891 non-null float64\n",
      "Ti_Mrs         891 non-null float64\n",
      "Ti_Other       891 non-null float64\n",
      "Ti_Rev         891 non-null float64\n",
      "dtypes: bool(1), float64(24), int64(6), object(7)\n",
      "memory usage: 265.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "titanic['Title_ct']=titanic.groupby(['Title'])['Title'].transform('count')\n",
    "titanic.loc[titanic.Title_ct<5,['Title']]='Other'\n",
    "\n",
    "titanic.Title.value_counts()\n",
    "\n",
    "titanic=pd.merge(titanic,pd.get_dummies(titanic.Title, prefix='Ti',dummy_na=False), on=titanic['PassengerId'])\n",
    "\n",
    "print titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic['NameTest']=titanic.Name\n",
    "titanic['NameTest'].replace(to_replace=\" \\(.*\\)\",value=\"\",inplace=True, regex=True)\n",
    "titanic['NameTest'].replace(to_replace=\", M.*\\.\",value=\", \",inplace=True, regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_list=pd.concat([titanic[['PassengerId','NameTest']]])\n",
    "name_list['Sp_ct']=name_list.groupby('NameTest')['NameTest'].transform('count')-1\n",
    "titanic=pd.merge(titanic,name_list[['PassengerId','Sp_ct']],on='PassengerId',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic.to_csv('./titanic_clean_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, the next step here would be to perform a univariate (and, for learners that do not naturally perform feature selection with interactions, potentially bivariate) analysis to see which features best predict the outcome. In some cases (Random Forests, Boosting trees) the learner naturally performs feature selection; in others (SVM, Logit, Naive Bayes), we rely on a univariate analysis pipelined into the algorithm to make these decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "gini\n",
      "sqrt\n",
      "9\n",
      "12\n",
      "0.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "execfile('./Final_setup_Random_Forest.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exponential\n",
      "0.29\n",
      "100\n",
      "3\n",
      "5\n",
      "11\n",
      "0.0\n",
      "1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "execfile('./Final_setup_GBoost.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "0.5\n",
      "0.826336341616\n"
     ]
    }
   ],
   "source": [
    "execfile('./Final_setup_SVM.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "execfile('./Final_setup_Logit.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "execfile('./Final_setup_NB.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rf_pred  gboost_pred  svm_pred  nb_pred  log_pred\n",
      "0        1            1         1        1         1\n",
      "1        1            1         1        1         1\n",
      "2        0            0         0        0         0\n",
      "3        0            0         1        1         0\n",
      "4        0            0         0        0         0\n",
      "              rf_pred  gboost_pred  svm_pred   nb_pred  log_pred\n",
      "rf_pred      1.000000     0.749622  0.796041  0.660271  0.840651\n",
      "gboost_pred  0.749622     1.000000  0.668922  0.513727  0.723178\n",
      "svm_pred     0.796041     0.668922  1.000000  0.568527  0.703526\n",
      "nb_pred      0.660271     0.513727  0.568527  1.000000  0.541967\n",
      "log_pred     0.840651     0.723178  0.703526  0.541967  1.000000\n"
     ]
    }
   ],
   "source": [
    "execfile('./Final_ensemble.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
