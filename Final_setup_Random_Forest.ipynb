{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script implements a Random Forest algorithm on the Titanic dataset. This is an algorithm that bootstraps both features and samples, and so will be auto-selecting features to evaluate. Since we're pretty agnostic about everything except prediction, let's just cycle through each of the option values to find some good ones (since we're not doing any backward evaluation after choosing an option, this probably isn't the optimal one, but it should be decent at least)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "titanic=pd.read_csv('./titanic_clean_data.csv')\n",
    "\n",
    "cols_to_norm=['Age','Fare']\n",
    "col_norms=['Age_z','Fare_z']\n",
    "\n",
    "titanic[col_norms]=titanic[cols_to_norm].apply(lambda x: (x-x.mean())/x.std())\n",
    "\n",
    "titanic['cabin_clean']=(pd.notnull(titanic.Cabin))\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import  GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "titanic_target=titanic.Survived.values\n",
    "features=['Sex','SibSp','Parch','Pclass_1','Pclass_2','Pclass_3','Emb_C','Emb_Q','Emb_S',\\\n",
    "                         'Emb_nan','Age_ct_C','Age_ct_A','Age_ct_S', 'Sp_ct','Age_z','Fare_z',\\\n",
    "                        'Ti_Dr', 'Ti_Master', 'Ti_Mil', 'Ti_Miss', 'Ti_Mr', 'Ti_Mrs', 'Ti_Other', 'Ti_Rev',\\\n",
    "                         'Fl_AB', 'Fl_CD', 'Fl_EFG', 'Fl_nan']\n",
    "titanic_features=titanic[features].values\n",
    "\n",
    "\n",
    "titanic_features, ensemble_features, titanic_target, ensemble_target= \\\n",
    "    train_test_split(titanic_features,\n",
    "                     titanic_target,\n",
    "                     test_size=.1,\n",
    "                     random_state=7132016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what we're going to do is go stepwise through many of the features of the random forest classifier, to figure out which parameters will give us the best fit. RF naturally does cross-validation in the default, so we don't need to worry about that part. We'll go in the following order:\n",
    "\n",
    "   * Number of Trees\n",
    "   * Loss Criterion\n",
    "   * max_features\n",
    "   * max_depth\n",
    "   * min_samples_split\n",
    "   * min_weight_fraction_leaf\n",
    "   * max_leaf_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.) Number of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "score=0\n",
    "scores=[]\n",
    "for feature in range(50,1001,50):\n",
    "    clf = RandomForestClassifier(n_estimators=feature, oob_score=True, random_state=7112016)\n",
    "    clf.fit(titanic_features,titanic_target)\n",
    "    score_test = clf.oob_score_\n",
    "    scores.append(score_test)\n",
    "    if score_test>score:\n",
    "        n_out=feature\n",
    "        score_diff=score_test-score\n",
    "        score=score_test\n",
    "\n",
    "\n",
    "print n_out        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.) Loss Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini\n"
     ]
    }
   ],
   "source": [
    "crit_param = ['gini','entropy']\n",
    "score=0\n",
    "for feature in crit_param:\n",
    "    clf = RandomForestClassifier(n_estimators=n_out, criterion=feature, oob_score=True, random_state=7112016)\n",
    "    clf.fit(titanic_features,titanic_target)\n",
    "    score_test = clf.oob_score_\n",
    "    if score_test>score:\n",
    "        crit_out=feature\n",
    "        score_diff=score_test-score\n",
    "        score=score_test\n",
    "\n",
    "print crit_out        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.) Number of features considered at each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqrt\n"
     ]
    }
   ],
   "source": [
    "feat_param = ['sqrt','log2',None]\n",
    "score=0\n",
    "for feature in feat_param:\n",
    "    clf = RandomForestClassifier(n_estimators=n_out, criterion=crit_out, max_features=feature,\\\n",
    "                                 oob_score=True, random_state=7112016)\n",
    "    clf.fit(titanic_features,titanic_target)\n",
    "    score_test = clf.oob_score_\n",
    "    if score_test>score:\n",
    "        max_feat_out=feature\n",
    "        score_diff=score_test-score\n",
    "        score=score_test\n",
    "\n",
    "print max_feat_out        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.) Maximum depth of tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "score=0\n",
    "for feature in range(1,21):\n",
    "    clf = RandomForestClassifier(n_estimators=n_out, criterion=crit_out, max_features=max_feat_out, \\\n",
    "                                 max_depth=feature, oob_score=True, random_state=7112016)\n",
    "    clf.fit(titanic_features,titanic_target)\n",
    "    score_test = clf.oob_score_\n",
    "    if score_test>score:\n",
    "        depth_out=feature\n",
    "        score_diff=score_test-score\n",
    "        score=score_test\n",
    "\n",
    "print depth_out        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.) The number of samples available in order to make another split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "score=0\n",
    "scores=[]\n",
    "for feature in range(1,21):\n",
    "    clf = RandomForestClassifier(n_estimators=n_out, criterion=crit_out,\\\n",
    "                                 max_features=max_feat_out, max_depth=depth_out,\\\n",
    "                                 min_samples_split=feature, oob_score=True, random_state=7112016)\n",
    "    clf.fit(titanic_features,titanic_target)\n",
    "    score_test = clf.oob_score_\n",
    "    scores.append(score_test)\n",
    "    if score_test>=score:\n",
    "        sample_out=feature\n",
    "        score_diff=score_test-score\n",
    "        score=score_test\n",
    "\n",
    "print sample_out        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.) Min required weighted fraction of samples in a leaf or node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "score=0\n",
    "\n",
    "for feature in np.linspace(0.0,0.5,10):\n",
    "    clf = RandomForestClassifier(n_estimators=n_out, criterion=crit_out,\\\n",
    "                                 max_features=max_feat_out, max_depth=depth_out,\\\n",
    "                                 min_samples_split=sample_out, min_weight_fraction_leaf=feature, \\\n",
    "                                 oob_score=True, random_state=7112016)\n",
    "    clf.fit(titanic_features,titanic_target)\n",
    "    score_test = clf.oob_score_\n",
    "    scores.append(score_test)\n",
    "    if score_test>score:\n",
    "        frac_out=feature\n",
    "        score_diff=score_test-score\n",
    "        score=score_test\n",
    "\n",
    "print frac_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.) Maximum possible number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#max_leaf_nodes - Note here we don't reset score because in order to use this variable we'll need to change other stuff\n",
    "\n",
    "node_out=None\n",
    "\n",
    "for feature in range(2,11):\n",
    "    clf = RandomForestClassifier(n_estimators=n_out, criterion=crit_out,\\\n",
    "                                 max_features=max_feat_out, max_depth=depth_out,\\\n",
    "                                 min_samples_split=sample_out, min_weight_fraction_leaf=frac_out, \\\n",
    "                                 max_leaf_nodes=feature, oob_score=True, random_state=7112016)\n",
    "    clf.fit(titanic_features,titanic_target)\n",
    "    score_test = clf.oob_score_\n",
    "    scores.append(score_test)\n",
    "    if score_test>score:\n",
    "        node_out=feature\n",
    "        score_diff=score_test-score\n",
    "        score=score_test\n",
    "\n",
    "print node_out\n",
    "\n",
    "model=RandomForestClassifier(n_estimators=n_out, criterion=crit_out,\\\n",
    "                                 max_features=max_feat_out, max_depth=depth_out,\\\n",
    "                                 min_samples_split=sample_out, min_weight_fraction_leaf=frac_out, \\\n",
    "                                 max_leaf_nodes=node_out, random_state=7112016).fit(titanic_features, titanic_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('./test.csv')\n",
    "\n",
    "test_data.Sex.replace(['male','female'],[True,False], inplace=True)\n",
    "test_data.Age= test_data.groupby(['Sex','Pclass'])[['Age']].transform(lambda x: x.fillna(x.mean()))\n",
    "test_data.Fare= titanic.groupby(['Pclass'])[['Fare']].transform(lambda x: x.fillna(x.mean()))\n",
    "titanic_class=pd.get_dummies(test_data.Pclass,prefix='Pclass',dummy_na=False)\n",
    "test_data=pd.merge(test_data,titanic_class,on=test_data['PassengerId'])\n",
    "test_data=pd.merge(test_data,pd.get_dummies(test_data.Embarked, prefix='Emb', dummy_na=True), on=test_data['PassengerId'])\n",
    "titanic['Floor']=titanic['Cabin'].str.extract('^([A-Z])', expand=False)\n",
    "titanic['Floor'].replace(to_replace='T',value=np.NaN ,inplace=True)\n",
    "titanic=pd.merge(titanic,pd.get_dummies(titanic.Floor, prefix=\"Fl\", dummy_na=True),on=titanic['PassengerId'])\n",
    "test_data['Age_cut']=pd.cut(test_data['Age'],[0,17.9,64.9,99], labels=['C','A','S'])\n",
    "test_data=pd.merge(test_data,pd.get_dummies(test_data.Age_cut, prefix=\"Age_ct\", dummy_na=False),on=test_data['PassengerId'])\n",
    "\n",
    "test_data['Title']=test_data['Name'].str.extract(', (.*)\\.', expand=False)\n",
    "test_data['Title'].replace(to_replace='Mrs\\. .*',value='Mrs', inplace=True, regex=True)\n",
    "test_data.loc[test_data.Title.isin(['Col','Major','Capt']),['Title']]='Mil'\n",
    "test_data.loc[test_data.Title=='Mlle',['Title']]='Miss'\n",
    "test_data.loc[test_data.Title=='Mme',['Title']]='Mrs'\n",
    "test_data['Title_ct']=test_data.groupby(['Title'])['Title'].transform('count')\n",
    "test_data.loc[test_data.Title_ct<5,['Title']]='Other'\n",
    "test_data=pd.merge(test_data,pd.get_dummies(test_data.Title, prefix='Ti',dummy_na=False), on=test_data['PassengerId'])\n",
    "\n",
    "test_data['NameTest']=test_data.Name\n",
    "test_data['NameTest'].replace(to_replace=\" \\(.*\\)\",value=\"\",inplace=True, regex=True)\n",
    "test_data['NameTest'].replace(to_replace=\", M.*\\.\",value=\", \",inplace=True, regex=True)\n",
    "\n",
    "\n",
    "cols_to_norm=['Age','Fare']\n",
    "col_norms=['Age_z','Fare_z']\n",
    "\n",
    "test_data['Age_z']=(test_data.Age-titanic.Age.mean())/titanic.Age.std()\n",
    "test_data['Fare_z']=(test_data.Fare-titanic.Fare.mean())/titanic.Fare.std()\n",
    "\n",
    "test_data['cabin_clean']=(pd.notnull(test_data.Cabin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_list=pd.concat([titanic[['PassengerId','NameTest']],test_data[['PassengerId','NameTest']]])\n",
    "name_list['Sp_ct']=name_list.groupby('NameTest')['NameTest'].transform('count')-1\n",
    "test_data=pd.merge(test_data,name_list[['PassengerId','Sp_ct']],on='PassengerId',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_cols(var_check,df):\n",
    "\n",
    "    if var_check not in df.columns.values:\n",
    "        df[var_check]=0\n",
    "\n",
    "for x in features:\n",
    "    add_cols(x, test_data)\n",
    "    \n",
    "features=['Sex','SibSp','Parch','Pclass_1','Pclass_2','Pclass_3','Emb_C','Emb_Q','Emb_S',\\\n",
    "                         'Emb_nan','Age_ct_C','Age_ct_A','Age_ct_S', 'Sp_ct','Age_z','Fare_z',\\\n",
    "                        'Ti_Dr', 'Ti_Master', 'Ti_Mil', 'Ti_Miss', 'Ti_Mr', 'Ti_Mrs', 'Ti_Other', 'Ti_Rev',\\\n",
    "                         'Fl_AB', 'Fl_CD', 'Fl_EFG', 'Fl_nan']\n",
    "test_features=test_data[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions=model.predict(ensemble_features)\n",
    "ensemble_rf=pd.DataFrame({'rf_pred':predictions})\n",
    "ensemble_rf.to_csv('./ensemble_rf.csv', index=False)\n",
    "\n",
    "predictions=model.predict(test_features)\n",
    "test_data['Survived']=predictions\n",
    "kaggle=test_data[['PassengerId','Survived']]\n",
    "kaggle.to_csv('./kaggle_titanic_submission_rf.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
