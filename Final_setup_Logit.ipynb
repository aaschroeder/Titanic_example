{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script implements a Logistic Classifier on the Titanic dataset. Like the SVM and Naive Bayes, we need to feed it the potentially relevant interaction features.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "titanic=pd.read_csv('./titanic_clean_data.csv')\n",
    "\n",
    "cols_to_norm=['Age','Fare']\n",
    "col_norms=['Age_z','Fare_z']\n",
    "\n",
    "titanic[col_norms]=titanic[cols_to_norm].apply(lambda x: (x-x.mean())/x.std())\n",
    "\n",
    "titanic['cabin_clean']=(pd.notnull(titanic.Cabin))\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.cross_validation import StratifiedKFold, train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "titanic['Gender']=titanic['Sex'].replace(to_replace=[True,False],value=['M','F'])\n",
    "titanic['Parch_ind']=titanic.Parch>=1\n",
    "titanic=pd.merge(titanic, pd.get_dummies(titanic['Gender'].str.cat(titanic['Pclass'].astype(str),sep='_')), on=titanic['PassengerId'])\n",
    "titanic=pd.merge(titanic, pd.get_dummies(titanic['Gender'].str.cat(titanic['Parch_ind'].astype(str),sep='_')), on=titanic['PassengerId'])\n",
    "titanic=pd.merge(titanic, pd.get_dummies(titanic['Gender'].str.cat(titanic['Age_cut'].astype(str),sep='_')), on=titanic['PassengerId'])\n",
    "\n",
    "\n",
    "\n",
    "titanic_target=titanic.Survived.values\n",
    "features=['Sex','SibSp','Parch','Pclass_1','Pclass_2','Pclass_3','Emb_C','Emb_Q','Emb_S',\\\n",
    "                         'Emb_nan','Age_ct_C','Age_ct_A','Age_ct_S', 'Sp_ct','Age_z','Fare_z',\\\n",
    "                        'Ti_Dr', 'Ti_Master', 'Ti_Mil', 'Ti_Miss', 'Ti_Mr', 'Ti_Mrs', 'Ti_Other', 'Ti_Rev',\\\n",
    "                         'Fl_AB', 'Fl_CD', 'Fl_EFG', 'Fl_nan',\\\n",
    "                         'F_1', 'F_2', 'F_3', 'M_1', 'M_2', 'M_3', 'F_False', 'F_True', 'M_False', 'M_True',\\\n",
    "                         'F_A', 'F_C', 'M_A', 'M_C', 'M_S']            \n",
    "titanic_features=titanic[features].values\n",
    "\n",
    "\n",
    "titanic_features, ensemble_features, titanic_target, ensemble_target= \\\n",
    "    train_test_split(titanic_features,\n",
    "                     titanic_target,\n",
    "                     test_size=.1,\n",
    "                     random_state=7132016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score=0\n",
    "\n",
    "for x in range(10,29):\n",
    "        var_filter=SelectKBest(f_classif)\n",
    "        clf=LogisticRegression()\n",
    "        pipe_svm = Pipeline([('anova', var_filter), ('NB', clf)])\n",
    "        pipe_svm.set_params(anova__k=x)\n",
    "        score_test = cross_validation.cross_val_score(pipe_svm, titanic_features, titanic_target, n_jobs=1, \\\n",
    "                                                       cv=StratifiedKFold(titanic_target, n_folds=10, shuffle=True, random_state=7132016))\n",
    "        if score_test.mean()>score:\n",
    "            score=score_test.mean()\n",
    "            k_out=x\n",
    " \n",
    "   \n",
    "    \n",
    "model=pipe_svm.set_params(anova__k=k_out).fit(titanic_features, titanic_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('./test.csv')\n",
    "\n",
    "test_data.Sex.replace(['male','female'],[True,False], inplace=True)\n",
    "test_data.Age= test_data.groupby(['Sex','Pclass'])[['Age']].transform(lambda x: x.fillna(x.mean()))\n",
    "test_data.Fare= titanic.groupby(['Pclass'])[['Fare']].transform(lambda x: x.fillna(x.mean()))\n",
    "titanic_class=pd.get_dummies(test_data.Pclass,prefix='Pclass',dummy_na=False)\n",
    "test_data=pd.merge(test_data,titanic_class,on=test_data['PassengerId'])\n",
    "test_data=pd.merge(test_data,pd.get_dummies(test_data.Embarked, prefix='Emb', dummy_na=True), on=test_data['PassengerId'])\n",
    "titanic['Floor']=titanic['Cabin'].str.extract('^([A-Z])', expand=False)\n",
    "titanic['Floor'].replace(to_replace='T',value=np.NaN ,inplace=True)\n",
    "titanic=pd.merge(titanic,pd.get_dummies(titanic.Floor, prefix=\"Fl\", dummy_na=True),on=titanic['PassengerId'])\n",
    "test_data['Age_cut']=pd.cut(test_data['Age'],[0,17.9,64.9,99], labels=['C','A','S'])\n",
    "test_data=pd.merge(test_data,pd.get_dummies(test_data.Age_cut, prefix=\"Age_ct\", dummy_na=False),on=test_data['PassengerId'])\n",
    "\n",
    "test_data['Title']=test_data['Name'].str.extract(', (.*)\\.', expand=False)\n",
    "test_data['Title'].replace(to_replace='Mrs\\. .*',value='Mrs', inplace=True, regex=True)\n",
    "test_data.loc[test_data.Title.isin(['Col','Major','Capt']),['Title']]='Mil'\n",
    "test_data.loc[test_data.Title=='Mlle',['Title']]='Miss'\n",
    "test_data.loc[test_data.Title=='Mme',['Title']]='Mrs'\n",
    "test_data['Title_ct']=test_data.groupby(['Title'])['Title'].transform('count')\n",
    "test_data.loc[test_data.Title_ct<5,['Title']]='Other'\n",
    "test_data=pd.merge(test_data,pd.get_dummies(test_data.Title, prefix='Ti',dummy_na=False), on=test_data['PassengerId'])\n",
    "\n",
    "test_data['NameTest']=test_data.Name\n",
    "test_data['NameTest'].replace(to_replace=\" \\(.*\\)\",value=\"\",inplace=True, regex=True)\n",
    "test_data['NameTest'].replace(to_replace=\", M.*\\.\",value=\", \",inplace=True, regex=True)\n",
    "\n",
    "\n",
    "cols_to_norm=['Age','Fare']\n",
    "col_norms=['Age_z','Fare_z']\n",
    "\n",
    "test_data['Age_z']=(test_data.Age-titanic.Age.mean())/titanic.Age.std()\n",
    "test_data['Fare_z']=(test_data.Fare-titanic.Fare.mean())/titanic.Fare.std()\n",
    "test_data['Gender']=test_data['Sex'].replace(to_replace=[True,False],value=['M','F'])\n",
    "test_data['Parch_ind']=test_data.Parch>=1\n",
    "test_data=pd.merge(test_data, pd.get_dummies(test_data['Gender'].str.cat(test_data['Pclass'].astype(str),sep='_')), on=test_data['PassengerId'])\n",
    "test_data=pd.merge(test_data, pd.get_dummies(test_data['Gender'].str.cat(test_data['Parch_ind'].astype(str),sep='_')), on=test_data['PassengerId'])\n",
    "test_data=pd.merge(test_data, pd.get_dummies(test_data['Gender'].str.cat(test_data['Age_cut'].astype(str),sep='_')), on=test_data['PassengerId'])\n",
    "\n",
    "\n",
    "test_data['cabin_clean']=(pd.notnull(test_data.Cabin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_list=pd.concat([titanic[['PassengerId','NameTest']],test_data[['PassengerId','NameTest']]])\n",
    "name_list['Sp_ct']=name_list.groupby('NameTest')['NameTest'].transform('count')-1\n",
    "test_data=pd.merge(test_data,name_list[['PassengerId','Sp_ct']],on='PassengerId',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_cols(var_check,df):\n",
    "\n",
    "    if var_check not in df.columns.values:\n",
    "        df[var_check]=0\n",
    "\n",
    "for x in features:\n",
    "    add_cols(x, test_data)\n",
    "    \n",
    "features=['Sex','SibSp','Parch','Pclass_1','Pclass_2','Pclass_3','Emb_C','Emb_Q','Emb_S',\\\n",
    "                         'Emb_nan','Age_ct_C','Age_ct_A','Age_ct_S', 'Sp_ct','Age_z','Fare_z',\\\n",
    "                        'Ti_Dr', 'Ti_Master', 'Ti_Mil', 'Ti_Miss', 'Ti_Mr', 'Ti_Mrs', 'Ti_Other', 'Ti_Rev',\\\n",
    "                         'Fl_AB', 'Fl_CD', 'Fl_EFG', 'Fl_nan',\\\n",
    "                         'F_1', 'F_2', 'F_3', 'M_1', 'M_2', 'M_3', 'F_False', 'F_True', 'M_False', 'M_True',\\\n",
    "                         'F_A', 'F_C', 'M_A', 'M_C', 'M_S']            \n",
    "test_features=test_data[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions=model.predict(ensemble_features)\n",
    "ensemble_nb=pd.DataFrame({'log_pred':predictions})\n",
    "ensemble_nb.to_csv('./ensemble_logit.csv', index=False)\n",
    "\n",
    "predictions=model.predict(test_features)\n",
    "test_data['Survived']=predictions\n",
    "kaggle=test_data[['PassengerId','Survived']]\n",
    "kaggle.to_csv('./kaggle_titanic_submission_logit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
